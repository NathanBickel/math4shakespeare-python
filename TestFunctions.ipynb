{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4072dd52",
   "metadata": {},
   "source": [
    "### functions: <br>\n",
    "cosine_similarity - cosine similarity of two vectors <br>\n",
    "great_circle_distance - great-circle distance of two coordinates <br>\n",
    "most_similar - similarities over matrices <br>\n",
    "place_composition - adds vectors corresponding with list of place names <br>\n",
    "place_join - find all places corresponding with name in a gazetteer <br>\n",
    "plot_timeseries - plots timeseries over place-year matrix <br>\n",
    "ppmi - calculates ppmi for matrix (positive pointwise mutual information) <br>\n",
    "semantic_footprint - semantic footprint of a term <br>\n",
    "similarity_map - creates semantic map of a keyword <br>\n",
    "<br>\n",
    "### data:<br>\n",
    "doc_metadata - EEBO doc metadata<br>\n",
    "eebo_network - EEBO booktrade network<br>\n",
    "geo - geographical metadata<br>\n",
    "kwic - EEBO keyword-in-context matrix<br>\n",
    "litmath<br>\n",
    "place_doc - places<br>\n",
    "term_doc - EEBO term-document matrix<br>\n",
    "<br>\n",
    "### other functions:<br>\n",
    "dot_product - dot product of two vectors<br>\n",
    "correlation - correlation between two vectors<br>\n",
    "variance<br>\n",
    "covariance<br>\n",
    "tf-idf - normalize a matrix usuing tf-idf<br>\n",
    "standard scoring<br>\n",
    "entropy<br>\n",
    "<br>\n",
    "k-means clustering<br>\n",
    "degree<br>\n",
    "betweenness<br>\n",
    "eigenvector centrality<br>\n",
    "transitivity/clustering coefficiant<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82ead28",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b844336b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 2.22044605e-16, 2.23143551e-01],\n",
       "       [2.22044605e-16, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.96121587e-02, 2.22044605e-16, 0.00000000e+00]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "matrix = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "\n",
    "#normalize matrix using positive pointwise mutual information\n",
    "#input matrix m, output normalized matrix\n",
    "def ppmi(m):\n",
    "    total = np.sum(m)\n",
    "    pcol = (np.sum(m, axis = 0)) / total\n",
    "    xlength = len(pcol)\n",
    "    pcol = np.reshape(pcol,(1,len(pcol)))\n",
    "    prow = (np.sum(m, axis = 1)) / total\n",
    "    ylength = len(prow)\n",
    "    prow = np.reshape(prow,(len(prow),1))\n",
    "    pm = prow@pcol\n",
    "    m = m / total\n",
    "    m = m / pm\n",
    "    m = np.log(m)\n",
    "    for x in range(0,ylength):\n",
    "        for y in range(0,xlength):\n",
    "            if m[x][y] < 0:\n",
    "                m[x][y] = 0\n",
    "    return m\n",
    "\n",
    "ppmi(matrix)\n",
    "\n",
    "    \n",
    "    \n",
    "#normalize matrix using tf-idf\n",
    "#input matrix m, out\n",
    "#def tfidf(m):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab8aed86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9746318461970762"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "x = [1,2,3]\n",
    "y = [4,5,6]\n",
    "\n",
    "def cosine_similarity(x,y) :\n",
    "    return (np.dot(x,y)) / (math.sqrt(np.dot(x,x)) * math.sqrt(np.dot(y,y)))\n",
    "\n",
    "cosine_similarity(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb9a3471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023718761330184128"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "x = [1,2,3]\n",
    "y = [4,5,6]\n",
    "\n",
    "def dotProduct(x: list, y: list) -> float:\n",
    "    # Should we just do `return np.dot(x,y)` instead?\n",
    "    if not len(x) == len(y):\n",
    "        raise Exception(\"Vectors are not the same length\")\n",
    "    x_arr = np.array(x)\n",
    "    y_arr = np.array(y)\n",
    "    return sum(x_arr * y_arr)\n",
    "    \n",
    "def variance(x) :\n",
    "    mean = sum(x)/len(x)\n",
    "    res = (x-mean)\n",
    "    return(var == (np.dot(res,res)) / len(x))\n",
    "    \n",
    "def covariance(x,y) :\n",
    "    meanx = sum(x)/len(x)\n",
    "    meany = sum(y)/len(y)\n",
    "    resx = (x-mean)\n",
    "    resy = (y-mean)\n",
    "    return(covar == (np.dot(resx,resy))/len(x))\n",
    "\n",
    "def correlation(x,y) :\n",
    "    return(covariance(x,y)/np.sqrt(variance(x)*variance(y)))\n",
    "    \n",
    "def standardScoring(x) :\n",
    "    mean = sum(x)/len(x)\n",
    "    sd = math.sqrt(variance(x))\n",
    "    return((x-mean)/sd)\n",
    "    \n",
    "def entropy(x: list) -> float:\n",
    "    x_arr = np.array(x)\n",
    "    px = x_arr/sum(x)\n",
    "    px = px[px != 0] # The values of px that are 0 will not contribute to the sum\n",
    "    logpx = np.log(px)\n",
    "    return(-dotProduct(px,logpx))\n",
    "\n",
    "def euc_distance(x,y) :\n",
    "    return math.sqrt(np.sum(np.subtract(x,y))**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9928187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# See https://en.wikipedia.org/wiki/Tf-idf#Definition for details on calculation\n",
    "def tfidf(term: str, document: str, corpus: pd.DataFrame) -> float:\n",
    "    # Find term-frequency of term\n",
    "    tf = corpus.loc[term, document]/corpus.values.sum()\n",
    "    # Find inverse document frequency\n",
    "    N = len(corpus.columns)\n",
    "    term_vec = corpus.loc[term]\n",
    "    docs_with_term = len(term_vec[term_vec != 0]) # Number of documents containing term\n",
    "    idf = np.log(N/docs_with_term)\n",
    "    return tf * idf\n",
    "\n",
    "# Method that returns a dataframe containg the tfidf for each term\n",
    "def tfidf_matrix(corpus: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create term-frequency matrix\n",
    "    tf = corpus/corpus.values.sum()\n",
    "    # Create inverse document frequency vector\n",
    "    N = len(corpus.columns)\n",
    "    doc_frequencies = np.array(corpus.apply(lambda row: len(row[row != 0]), axis=1))\n",
    "    idf = np.log(N/doc_frequencies)\n",
    "    return tf.multiply(idf, axis='rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5a4e65a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Ham  MND  1H4\n",
      "love    5    9    0\n",
      "hate    4    8    1\n",
      "king    0    0    9\n",
      "           Ham       MND       1H4\n",
      "love  0.056315  0.101366  0.000000\n",
      "hate  0.000000  0.000000  0.000000\n",
      "king  0.000000  0.000000  0.274653\n"
     ]
    }
   ],
   "source": [
    "# Testing tfidf\n",
    "corpus = pd.DataFrame(np.array([[5,9,0],[4,8,1],[0,0,9]]),\n",
    "                      columns=['Ham','MND','1H4'],\n",
    "                      index=['love','hate','king'])\n",
    "print(corpus)\n",
    "print(tfidf_matrix(corpus))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e15d02da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5])\n",
    " \n",
    "applyall = np.vectorize(lambda i: i + 2)\n",
    "res = applyall(arr)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b181c3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3828950259.py, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 29\u001b[1;36m\u001b[0m\n\u001b[1;33m    if(class(mat) == \"docMatrix\"):\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\"\"\" 'most_similar' parameters:\n",
    "m - mat\n",
    "    word matrix as a pandas dataframe\n",
    "v - vec\n",
    "    vector to evaluate\n",
    "method - str\n",
    "    similarity to be performed, by default 'cosine' ex: \n",
    "margin - int\n",
    "    0 to calculate over rows, 1 over columns\n",
    "fullResults - boolean\n",
    "    by default false\n",
    "\"\"\"\n",
    "\n",
    "def cosine_similarity(x,y) :\n",
    "    return (np.dot(x,y)) / (math.sqrt(np.dot(x,x)) * math.sqrt(np.dot(y,y)))\n",
    "\n",
    "def euc_distance(x,y) :\n",
    "    return math.sqrt(np.sum(np.subtract(x,y))**2)\n",
    "\n",
    "\n",
    "def most_similar(mat, vec, method = \"cosine\", margin = 0, fullResults = False):\n",
    "    cos_sim = cosine_similarity(x,y)\n",
    "    euc_dist = euc_distance(x,y)\n",
    "    \n",
    "    if(class(mat) == \"docMatrix\"):\n",
    "        mat = np.matmul(mat,mat)\n",
    "        \n",
    "    if(np.isin(len(vec),mat.shape) == False):\n",
    "        keyword = vec\n",
    "        if(margin == 0):\n",
    "            if(np.isin(keyword,list(mat.rows)) == False):\n",
    "                raise Exception(\"Your keyword doesn't match any of your matrix's row names.\")\n",
    "            vec = mat.loc[keyword]\n",
    "        if(margin == 1):\n",
    "            if(np.isin(keyword,list(mat.columns)) == False):\n",
    "                raise Exception(\"Your keyword doesn't match any of your matrix's column names.\")\n",
    "            vec = mat[keyword]\n",
    "        \n",
    "        if(np.isin(method, list(\"cosine\",\"euclidean\", \"covariance\", \"pearson\") == False)):\n",
    "            raise Exception(\"Method must be specified as 'cosine', 'euclidean', 'covariance', or 'pearson'.\")\n",
    "        if(method == \"cosine\"):\n",
    "            #results = apply(mat, margin, cos_sim, vec)\n",
    "            results = mat.apply(cos_sim, axis=margin)\n",
    "        if(method == \"euclidean\"):\n",
    "            #results = apply(mat, margin, euc_dist, vec)\n",
    "            results = mat.apply(euc_dist, axis=margin)\n",
    "        if(method == \"covariance\"):\n",
    "            #results = apply(mat, margin, np.cov, vec)\n",
    "            \n",
    "        if(method == \"pearson\"):\n",
    "            results = apply(mat, margin, correlation, vec)\n",
    "            \n",
    "        if(fullResults == False):\n",
    "            if(len(vec) == 1):\n",
    "                results = results[-np.where(results.columns == vec)]\n",
    "            if(method == \"euclidean\"):\n",
    "                results = results.sort()[0:11]\n",
    "            else:\n",
    "                results = results.sort(reverse=True)[0:11]\n",
    "        return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e3535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def degrees_to_radians(x) :\n",
    "    return(x*math.pi/180)\n",
    "    \n",
    "def great_circle_distance(lon1, lat1, lon2, lat2, radius = 3437) :\n",
    "    lon1 = degrees_to_radians(lon1)\n",
    "    lat1 = degrees_to_radians(lat1)\n",
    "    lon2 = degrees_to_radians(lon2)\n",
    "    lat2 = degrees_to_radians(lat2)\n",
    "    d = math.acos(math.sin(lat1)*math.sin(lat2) + math.cos(lat1)*math.cos(lat2) * math.cos(lon2-lon1)) * radius\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4cf188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Adds vectors corresponding to a list of place names\n",
    "def place_composition(mat, places) :\n",
    "    places = places[np.isin(mat.rows)]\n",
    "    if(len(places) > 1):\n",
    "        mat = mat.loc[places] #[,places]\n",
    "        mat = as.matrix(mat)\n",
    "        vec = np.sum(mat, axis=1)\n",
    "    else:\n",
    "        vec = mat[places] #[places,]\n",
    "    return vec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c89bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_join(places, gaz) :\n",
    "    places = list(places,gaz)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40401266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb18425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_footprint() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_map() :"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "73777277ffe1eb9718db2f7ff3a495dee19e3d7886774dea57bf006966fae6c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
